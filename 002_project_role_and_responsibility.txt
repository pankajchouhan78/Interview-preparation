1. Project: Thirdi-AI (Advertising Analytics Platform)

Thirdi is a platform that connects multiple ad networks like Facebook, Google Ads, LinkedIn, TikTok, and Google Analytics into a single dashboard. Instead of checking each platform separately, marketing team can see all their campaign data in one place.

The system automatically pulls campaign data such as impressions, clicks, spend, and conversions from these ad networks. Since every platform provides data in a different format, Thirdi first normalizes the data and converts it into a common structure.

All data is organized by workspace, which represents a company or team. Each workspace can have its own users, ad accounts, and preferred currency. The platform also converts all costs into the workspace’s currency so performance comparisons are accurate.

Using this clean and combined data, Thirdi generates reports and analytics like campaign performance, funnels, and audience breakdowns. It also uses AI to provide recommendations on how to improve ad performance, such as optimizing budgets or improving click-through rates.

In addition, Thirdi sends alerts when something unusual happens, like a sudden increase in spend or a drop in conversions. Overall, Thirdi helps businesses clearly see how their ads are performing, take quicker actions, and spend their ad budget more effectively.


Technologies used:
In this project, I used Django and Django REST Framework to develop backend APIs, Celery with Redis to schedule background sync jobs, and integrated Marketing APIs for Facebook, Google, TikTok, and LinkedIn.

My Responsibilities:
In this project, my responsibilities were:
1. Developing backend APIs using Django & DRF.
2. Integrating multiple ad network APIs for automated campaign data collection.
3. Implementing Celery & Redis for background task scheduling.

In this project, I used Django and Django REST Framework to build backend APIs, Celery with Redis for background task automation, Docker for containerization and secure permission handling, and PostgreSQL for data storage and reporting.
My Responsibilities:
In this project, my responsibilities were:
Developing REST APIs using Django & DRF for shipment tracking, status updates, and user role management.
Using Celery with Redis to automate background tasks such as real-time shipment alerts and route recalculations.
Designing PostgreSQL schemas for storing shipment logs, user activity, and tracking history.
Writing aggregation logic to generate performance and operational reports for the logistics team.

—-------------------------------------

2. Project: ProcureMate (AI-based Tender Management Platform)
What it does:
ProcureMate is an AI-based tender management platform built for petroleum companies like Bharat Petroleum and Indian Oil. 

The platform allows multiple vendors to apply for multiple tenders by submitting their bids and required documents. such as asset availability, financial strength, and past experience. 

All bid data is processed by an AI system that evaluates bids in three steps, such as eligibility checks, financial and technical comparison, and final shortlisting.

It also automates tender listing, bid submission, and compliance document handling.This helps in selecting the most suitable vendor and makes the tender process faster, transparent, and efficient.


My Responsibilities:
In this project, my responsibilities were:
1. Developing  backend APIs using FastAPI for vendor registration, tender listings, and bid submissions.
2. Designing and managing the relational database schema on AWS RDS.
3. Implementing AWS S3 for secure storage and access of large compliance documents.
4. Deploying the application on AWS EC2 and setting up CI/CD pipelines for automated deployment.


Yha par multiple tenders niklte h or multiple bidders apn apn bid lagate h then yeh data ai ke pass jata h 
Yha per ai step in hota h or tin steps me processing hoti h bid filter karne ke liye uske bad last step me hume select bid ki list milti or usko tender mil jata hai.
